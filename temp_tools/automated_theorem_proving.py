import logging
import json
import random
from typing import List, Dict, Any
from tools.base_tool import BaseTool

# Deferring heavy imports
try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    logging.warning("transformers library not found. Automated theorem proving tools will not be available.")

logger = logging.getLogger(__name__)

class TheoremProvingModel:
    """Manages the text generation model for theorem proving tasks, using a singleton pattern."""
    _generator = None
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(TheoremProvingModel, cls).__new__(cls)
            if not TRANSFORMERS_AVAILABLE:
                logger.error("Required libraries for theorem proving are not installed. Please install 'transformers' and 'torch'.")
                return cls._instance # Return instance without generator
            
            if cls._generator is None:
                try:
                    logger.info("Initializing text generation model (gpt2) for theorem proving...")
                    cls._generator = pipeline("text-generation", model="gpt2")
                    logger.info("Text generation model loaded.")
                except Exception as e:
                    logger.error(f"Failed to load text generation model: {e}")
        return cls._instance

    def generate_response(self, prompt: str, max_length: int) -> str:
        if not self._generator:
            return "Text generation model not available. Check logs for loading errors."
        
        try:
            generated = self._generator(prompt, max_length=max_length, num_return_sequences=1, pad_token_id=self._generator.tokenizer.eos_token_id)[0]['generated_text']
            # Clean up the output from the model, removing the prompt
            return generated.replace(prompt, "").strip()
        except Exception as e:
            logger.error(f"Text generation failed: {e}")
            return f"Error during text generation: {e}"

theorem_proving_model_instance = TheoremProvingModel()

class ProveTheoremTool(BaseTool):
    """Proves a mathematical theorem or logical statement using an AI model."""
    def __init__(self, tool_name="prove_theorem"):
        super().__init__(tool_name=tool_name)

    @property
    def description(self) -> str:
        return "Proves a mathematical theorem or logical statement, returning whether it's provable and a list of simulated proof steps generated by an AI model."

    @property
    def parameters(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {"statement": {"type": "string", "description": "The mathematical theorem or logical statement to prove."}},
            "required": ["statement"]
        }

    def execute(self, statement: str, **kwargs: Any) -> str:
        if not TRANSFORMERS_AVAILABLE:
            return json.dumps({"error": "This tool requires 'transformers' library to be installed."})

        prompt = f"Provide a step-by-step proof for the following mathematical theorem or logical statement: '{statement}'. If it is not provable, state that and explain why. Proof:"
        
        generated_proof = theorem_proving_model_instance.generate_response(prompt, max_length=len(prompt.split()) + 300)
        
        # Simple heuristic to determine provability from generated text
        is_provable = "not provable" not in generated_proof.lower() and "contradiction" not in generated_proof.lower() and "false" not in generated_proof.lower()
        
        report = {
            "statement": statement,
            "is_provable": is_provable,
            "proof_steps": generated_proof.split('\n') # Split into steps
        }
        return json.dumps(report, indent=2)

class FindCounterexampleTool(BaseTool):
    """Finds a counterexample to a mathematical theorem or logical statement using an AI model."""
    def __init__(self, tool_name="find_counterexample"):
        super().__init__(tool_name=tool_name)

    @property
    def description(self) -> str:
        return "Finds a counterexample to a given mathematical theorem or logical statement, if one exists, using an AI model."

    @property
    def parameters(self) -> Dict[str, Any]:
        return {
            "type": "object",
            "properties": {"statement": {"type": "string", "description": "The mathematical theorem or logical statement to find a counterexample for."}},
            "required": ["statement"]
        }

    def execute(self, statement: str, **kwargs: Any) -> str:
        if not TRANSFORMERS_AVAILABLE:
            return json.dumps({"error": "This tool requires 'transformers' library to be installed."})

        prompt = f"Find a specific counterexample to the following mathematical theorem or logical statement: '{statement}'. If no simple counterexample exists, state that. Counterexample:"
        
        generated_counterexample = theorem_proving_model_instance.generate_response(prompt, max_length=len(prompt.split()) + 150)
        
        # Simple heuristic to determine if a counterexample was found
        has_counterexample = "no simple counterexample" not in generated_counterexample.lower() and "not exist" not in generated_counterexample.lower() and "true" not in generated_counterexample.lower()
        
        report = {
            "statement": statement,
            "has_counterexample": has_counterexample,
            "counterexample": generated_counterexample
        }
        return json.dumps(report, indent=2)